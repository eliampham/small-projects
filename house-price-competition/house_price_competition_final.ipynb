{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SySn7W4NXE18"
      },
      "source": [
        "# Set up environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5H4dD5k1P90",
        "outputId": "17d80851-318f-4826-f1c0-52eb43cab306"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /drive\n",
            "/drive/MyDrive/Colab Notebooks/Projects/House Price Competition\n"
          ]
        }
      ],
      "source": [
        "# Import the 'drive' module from the 'google.colab' package to enable Google Drive integration.\n",
        "# Then, mount Google Drive to the '/drive' directory within the Colab environment.\n",
        "# The 'force_remount=True' parameter ensures that the Drive is remounted even if it was previously mounted.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/drive', force_remount=True)\n",
        "\n",
        "# This allows easy access to files stored in Google Drive.\n",
        "%cd '/drive/MyDrive/Colab Notebooks/Projects/House Price Competition'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCopERxXyPqH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.plotting.register_matplotlib_converters()\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# bmh makes more visual appealing\n",
        "plt.style.use('bmh')\n",
        "\n",
        "# set seed for reproducibility\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cIDM0POKsyI"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "7i4KX5PuzXEz"
      },
      "outputs": [],
      "source": [
        "# the test.csv file has no actual sales price for the competition purpose. So we need to split the trainning dataset into training and validation datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# load the data\n",
        "X = pd.read_csv('train.csv', index_col='Id')\n",
        "X_test = pd.read_csv('test.csv', index_col='Id') # there's no target in here for the competition purpose\n",
        "\n",
        "# remove rows with missing target â€“ SalePrice\n",
        "X.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
        "\n",
        "# separate target from predictors\n",
        "y = X.SalePrice\n",
        "X.drop(['SalePrice'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check if training and testing datasets have the same format\n",
        "print(X.shape)\n",
        "print(X_test.shape)\n",
        "print(X.columns.equals(X_test.columns))\n",
        "\n",
        "cat_cols = [col for col in X.columns if X[col].dtype == 'object']\n",
        "print(len(cat_cols))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osFQXWQ9U6DJ",
        "outputId": "e8676d9e-b32c-441a-eac7-d19ea8168dd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1460, 79)\n",
            "(1459, 79)\n",
            "True\n",
            "43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jmj0s910dhrn"
      },
      "source": [
        "# Preliminary Investigation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "G3GImsw_dqEu",
        "outputId": "9bf85398-d9cf-4c44-a491-229360270871"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1460, 79)\n",
            "Percentage of missing values: 6.79%\n",
            "LotFrontage      259\n",
            "Alley           1369\n",
            "MasVnrType       872\n",
            "MasVnrArea         8\n",
            "BsmtQual          37\n",
            "BsmtCond          37\n",
            "BsmtExposure      38\n",
            "BsmtFinType1      37\n",
            "BsmtFinType2      38\n",
            "Electrical         1\n",
            "FireplaceQu      690\n",
            "GarageType        81\n",
            "GarageYrBlt       81\n",
            "GarageFinish      81\n",
            "GarageQual        81\n",
            "GarageCond        81\n",
            "PoolQC          1453\n",
            "Fence           1179\n",
            "MiscFeature     1406\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# shape of training data (num_rows, num_columns)\n",
        "print(X.shape)\n",
        "\n",
        "# X.info()\n",
        "\n",
        "# calculate percentage of missing value\n",
        "total_cells = np.product(X.shape)\n",
        "missing_value_cols = X.isnull().sum()\n",
        "total_missing_cells = missing_value_cols.sum()\n",
        "missing_percentage = total_missing_cells / total_cells * 100\n",
        "print('Percentage of missing values: ' + str(format(missing_percentage, '.2f')) + '%')\n",
        "print(missing_value_cols[missing_value_cols > 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8CDwho8Xtr9",
        "outputId": "6f6ddfc8-a9cd-4baf-b697-75b9d1f2f2d3",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numerical columns with missing value:\n",
            "LotFrontage    259\n",
            "MasVnrArea       8\n",
            "GarageYrBlt     81\n",
            "dtype: int64\n",
            "3\n",
            "Categorical columns with missing value:\n",
            "Alley           1369\n",
            "MasVnrType       872\n",
            "BsmtQual          37\n",
            "BsmtCond          37\n",
            "BsmtExposure      38\n",
            "BsmtFinType1      37\n",
            "BsmtFinType2      38\n",
            "Electrical         1\n",
            "FireplaceQu      690\n",
            "GarageType        81\n",
            "GarageFinish      81\n",
            "GarageQual        81\n",
            "GarageCond        81\n",
            "PoolQC          1453\n",
            "Fence           1179\n",
            "MiscFeature     1406\n",
            "dtype: int64\n",
            "16\n"
          ]
        }
      ],
      "source": [
        "# numerical columns with missing value\n",
        "missing_value_num_cols = [col for col in X.columns if X[col].dtype != 'object' and X[col].isnull().sum() > 0]\n",
        "print('Numerical columns with missing value:')\n",
        "print(X[missing_value_num_cols].isnull().sum())\n",
        "print(len(missing_value_num_cols))\n",
        "\n",
        "# categorical columns with missing value\n",
        "missing_value_cat_cols = [col for col in X.columns if X[col].dtype == 'object' and X[col].isnull().sum()]\n",
        "print('Categorical columns with missing value:')\n",
        "print(X[missing_value_cat_cols].isnull().sum())\n",
        "print(len(missing_value_cat_cols))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# examine one feature in detail\n",
        "feature = 'Electrical'\n",
        "unique_values = X[feature].unique()\n",
        "print(unique_values)\n",
        "# Total count of values in the 'Electrical' column\n",
        "total_count = X[feature].count()\n",
        "\n",
        "# Count of occurrences of the specific value\n",
        "count = X[feature].value_counts()[unique_values[0]]\n",
        "\n",
        "# Calculate the percentage\n",
        "percentage = (count / total_count) * 100\n",
        "\n",
        "# Print the result\n",
        "print('Percentage of the first value:', format(percentage,'.2f'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUIppRA4ajuf",
        "outputId": "6c755ccd-15a5-4b78-c6ad-752ce3bec96e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['SBrkr' 'FuseF' 'FuseA' 'FuseP' 'Mix' nan]\n",
            "Percentage of the first value: 91.43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUG-nr67ZGve"
      },
      "source": [
        "# Handle Missing Value and Encode Categorical Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBXavZMBb74K"
      },
      "source": [
        "### Create a Data Process Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "import pandas as pd\n",
        "\n",
        "# Identify numerical and categorical columns\n",
        "numerical_cols = [col for col in X.columns if X[col].dtype != 'object']\n",
        "categorical_cols = [col for col in X.columns if X[col].dtype == 'object']\n",
        "\n",
        "# Preprocessing for numerical data (mean imputation)\n",
        "numerical_transformer = SimpleImputer(strategy='mean')\n",
        "\n",
        "# Create OrdinalEncoder instance for categorical data\n",
        "ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "\n",
        "# Preprocessing for categorical data\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),  # Fill with string\n",
        "    ('ordinal', ordinal_encoder)  # Use OrdinalEncoder\n",
        "])\n",
        "\n",
        "# Bundle preprocessing for numerical and categorical data\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Choose a training model\n",
        "model = XGBRegressor(n_estimators=500, learning_rate=0.05, random_state=0)\n",
        "\n",
        "# Bundle preprocessing and modeling code in a pipeline\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', model)\n",
        "])"
      ],
      "metadata": {
        "id": "jxaz0yy7AWi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boP30e9hdb5D"
      },
      "source": [
        "### Apply Cross-Validation to Evaluate the Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-6csfDkdkuk",
        "outputId": "2a22dea5-782c-4360-e9a6-a36d85708ac7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Cross-Validation Score (MAE): 16357.951607983734\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# X is broken into 5 folds (80% of X for training, 20% of X for validation, and do 5 interations)\n",
        "cv_scores = cross_val_score(pipeline, X, y, cv=5, scoring='neg_mean_absolute_error')\n",
        "\n",
        "# Print the average cross-validation score\n",
        "print('Mean Cross-Validation Score (MAE):', -cv_scores.mean())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdg4pKgvHhDa"
      },
      "source": [
        "**Results:**\n",
        "- RandomForestRegressor, n_estimator = 100: Mean Cross-Validation Score (MAE): 17635.59697260274\n",
        "- RandomForestRegressor, n_estimator = 500: Mean Cross-Validation Score (MAE): 17625.086326027398\n",
        "- XGBRegressor: Mean Cross-Validation Score (MAE): 16357.951607983734\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply the Pipeline"
      ],
      "metadata": {
        "id": "_O2sDgilmdo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the entire pipeline on training data\n",
        "pipeline.fit(X, y)  # Fit directly on original data\n",
        "\n",
        "# Transform the training data and test data\n",
        "# X_transformed = pipeline.named_steps['preprocessor'].transform(X)\n",
        "# X_test_transformed = pipeline.named_steps['preprocessor'].transform(X_test)\n",
        "X_transformed = pipeline[:-1].transform(X)\n",
        "X_test_transformed = pipeline[:-1].transform(X_test)\n",
        "\n",
        "# Get feature names after encoding\n",
        "feature_names = pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
        "\n",
        "# Remove prefixes from feature names\n",
        "feature_names = [name.split('__')[-1] for name in feature_names]\n",
        "\n",
        "# Convert to DataFrame and assign column names\n",
        "X_transformed = pd.DataFrame(X_transformed, columns=feature_names)\n",
        "X_test_transformed = pd.DataFrame(X_test_transformed, columns=feature_names)\n",
        "\n",
        "# Check if columns in transformed datasets are equal\n",
        "print(X_transformed.columns.equals(X_test_transformed.columns))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wY8a6wXC8bA",
        "outputId": "b5db42d7-f444-4699-fe77-bb8619e93e54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on test data and save to file for submission\n",
        "test_preds = pipeline.predict(X_test_transformed)\n",
        "\n",
        "output = pd.DataFrame({'Id': X_test.index,\n",
        "                       'SalePrice': test_preds})\n",
        "output.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "D0tn_QnpB9L2"
      },
      "execution_count": 74,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}